import requests
import re
import json
import random
import os

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ ---
SOURCE_URL = "https://iptv-org.github.io/iptv/index.m3u"
OUTPUT_FILE = "database.json" # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø©

# Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©
ARABIC_KEYWORDS = [
    "Jordan", "KSA", "Egypt", "Palestine", "UAE", "Dubai", 
    "Qatar", "Kuwait", "Lebanon", "Iraq", "Morocco", 
    "Tunisia", "Algeria", "Rotana", "MBC", "BeIN", "Sport", "News", "Syria"
]

# Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© ÙÙŠ Ø­Ø§Ù„ Ø¹Ø¯Ù… ØªÙˆÙØ± Ø´Ø¹Ø§Ø± Ù„Ù„Ù‚Ù†Ø§Ø©
ICONS = {
    "Sports": "https://img.icons8.com/3d-fluency/94/football-2.png",
    "News": "https://img.icons8.com/3d-fluency/94/news.png",
    "Movies": "https://img.icons8.com/3d-fluency/94/cinema-.png",
    "Kids": "https://img.icons8.com/3d-fluency/94/homer-simpson.png",
    "Religious": "https://img.icons8.com/3d-fluency/94/mosque.png",
    "Default": "https://img.icons8.com/3d-fluency/94/tv.png"
}

# Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ‡Ù…ÙŠØ© "Ø°ÙƒÙŠØ©" Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬
PROGRAMS = {
    "Sports": ["Ø§Ø³ØªÙˆØ¯ÙŠÙˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„", "Ù…Ø¨Ø§Ø±Ø§Ø© Ø§Ù„Ù‚Ù…Ø© (Ù…Ø¨Ø§Ø´Ø±)", "Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù", "ØµØ¨Ø§Ø­ Ø§Ù„Ø±ÙŠØ§Ø¶Ø©", "Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø§Ù„Ù…Ø´ØªØ¹Ù„"],
    "News": ["Ù†Ø´Ø±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", "Ø­ÙˆØ§Ø± Ø®Ø§Øµ", "Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ Ø§Ù„ÙŠÙˆÙ…", "Ù…ÙˆØ¬Ø² Ø§Ù„Ø£Ù†Ø¨Ø§Ø¡", "ØªØºØ·ÙŠØ© Ø®Ø§ØµØ©"],
    "Movies": ["ÙÙŠÙ„Ù… Ø§Ù„Ø³Ù‡Ø±Ø©: Ø£ÙƒØ´Ù†", "Ø³ÙŠÙ†Ù…Ø§ ÙƒÙ„Ø§Ø³ÙŠÙƒ", "Ù†Ø¬ÙˆÙ… Ù‡ÙˆÙ„ÙŠÙˆØ¯", "ÙÙŠÙ„Ù… Ø¹Ø±Ø¨ÙŠ Ø­ØµØ±ÙŠ", "Ø¹Ø±Ø¶ Ø£ÙˆÙ„"],
    "Kids": ["ÙƒØ±ØªÙˆÙ† Ø§Ù„ØµØ¨Ø§Ø­", "Ù…ØºØ§Ù…Ø±Ø§Øª Ø´ÙŠÙ‚Ø©", "ØªØ¹Ù„Ù… ÙˆÙ…Ø±Ø­", "Ø£Ø¨Ø·Ø§Ù„ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„", "Ø­ÙƒØ§ÙŠØ§Øª Ù‚Ø¨Ù„ Ø§Ù„Ù†ÙˆÙ…"],
    "Default": ["Ø¨Ø« Ù…Ø¨Ø§Ø´Ø±", "Ø¨Ø±Ù†Ø§Ù…Ø¬ Ù…Ù†ÙˆØ¹", "ÙÙˆØ§ØµÙ„ Ù…ÙˆØ³ÙŠÙ‚ÙŠØ©", "Ø¥Ø¹Ø§Ø¯Ø©", "Ø¬ÙˆÙ„Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§"]
}

DESCRIPTIONS = [
    "Ø¨Ø« Ù…Ø¨Ø§Ø´Ø± Ø¨Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ© - ØªØ§Ø¨Ø¹ Ø£Ø­Ø¯Ø« Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬.",
    "Ù‚Ù†Ø§Ø© Ø§Ù„Ø¹Ø§Ø¦Ù„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ù…Ø³Ù„Ø³Ù„Ø§Øª ÙˆØ¨Ø±Ø§Ù…Ø¬ ØªØ±ÙÙŠÙ‡ÙŠØ©.",
    "ØªØºØ·ÙŠØ© Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ø³Ø§Ø¹Ø©.",
    "Ø£Ù‚ÙˆÙ‰ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ø­ØµØ±ÙŠØ©.",
    "Ø£ÙÙ„Ø§Ù… Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¹Ø§Ù„Ù…ÙŠØ© Ù…ØªØ±Ø¬Ù…Ø© - Ø³ÙŠÙ†Ù…Ø§ ÙÙŠ Ø¨ÙŠØªÙƒ."
]

def detect_category(name, group):
    n = name.lower()
    g = group.lower() if group else ""
    if re.search(r'(sport|soccer|football|koora|bein|espn)', n) or "sport" in g: return "Sports"
    if re.search(r'(news|jazeera|arabia|cnn|bbc)', n) or "news" in g: return "News"
    if re.search(r'(movie|film|cinema|drama|action)', n) or "movie" in g: return "Movies"
    if re.search(r'(kid|cartoon|disney|spacetoon)', n) or "kids" in g: return "Kids"
    if re.search(r'(quran|sunnah|iqra)', n): return "Religious"
    return "Variety"

def is_arabic_priority(name, group):
    combined = (name + " " + group).lower()
    for key in ARABIC_KEYWORDS:
        if key.lower() in combined:
            return True
    return False

def generate_mock_data(category):
    # ØªÙˆÙ„ÙŠØ¯ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª ÙˆÙ‡Ù…ÙŠØ© ØªØ¨Ø¯Ùˆ Ø­Ù‚ÙŠÙ‚ÙŠØ© (Ø¹Ø§Ù„ÙŠØ© Ù„Ù„Ø±ÙŠØ§Ø¶Ø© ÙˆØ§Ù„Ø£Ø®Ø¨Ø§Ø±)
    base_views = 50000 if category in ["Sports", "News"] else 5000
    views = random.randint(base_views, base_views * 5)
    
    program = random.choice(PROGRAMS.get(category, PROGRAMS["Default"]))
    desc = random.choice(DESCRIPTIONS)
    likes = random.randint(100, 5000)
    
    return views, program, desc, likes

def main():
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ...")
    
    try:
        print(f"ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ØµØ¯Ø±: {SOURCE_URL}")
        r = requests.get(SOURCE_URL, timeout=45)
        r.raise_for_status()
        
        arabs = []
        others = []
        seen_names = set()
        
        lines = r.text.splitlines()
        current = {}
        
        for line in lines:
            line = line.strip()
            if not line: continue
            
            if line.startswith("#EXTINF:"):
                info = line[8:]
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³Ù…
                name_parts = info.split(',')
                name = name_parts[-1].strip()
                
                # Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
                if name in seen_names: continue
                seen_names.add(name)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø¹Ø§Ø±
                logo_m = re.search(r'tvg-logo="([^"]*)"', info)
                logo = logo_m.group(1) if logo_m else ""
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
                group_m = re.search(r'group-title="([^"]*)"', info)
                group = group_m.group(1) if group_m else ""
                
                # Ø§Ù„ØªØµÙ†ÙŠÙ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                cat = detect_category(name, group)
                
                # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø´Ø¹Ø§Ø± Ø§Ù„Ù…ÙÙ‚ÙˆØ¯
                final_logo = logo if logo.startswith('http') else ICONS.get(cat, ICONS["Default"])
                
                # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©
                views, prog, desc, likes = generate_mock_data(cat)
                
                # ÙØ­Øµ Ù‡Ù„ Ø§Ù„Ù‚Ù†Ø§Ø© Ø¹Ø±Ø¨ÙŠØ©ØŸ
                is_arab = is_arabic_priority(name, group)
                if is_arab:
                    views += 100000 # Ø¯ÙØ¹Ø© Ù‚ÙˆÙŠØ© Ù„Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„ØªØ¸Ù‡Ø± ÙÙŠ "Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø´Ø§Ù‡Ø¯Ø©"
                
                current = {
                    "name": name,
                    "logo": final_logo,
                    "category": cat,
                    "group": group,
                    "is_arabic": is_arab,
                    "views": views,
                    "likes": likes,
                    "program": prog,
                    "description": desc
                }
                
            elif not line.startswith("#") and current:
                url = line
                # ÙÙ„ØªØ±Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: Ù†ÙØ¶Ù„ HTTPS Ù„ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ GitHub Pages
                if url.startswith('http'):
                    current['url'] = url
                    
                    if current['is_arabic']:
                        arabs.append(current)
                    else:
                        others.append(current)
                
                current = {}

        # Ø§Ù„ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª (Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©)
        arabs.sort(key=lambda x: x['views'], reverse=True)
        others.sort(key=lambda x: x['views'], reverse=True)
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ù‚Ø§Ø¦Ù…ØªÙŠÙ†: Ø§Ù„Ø¹Ø±Ø¨ Ø£ÙˆÙ„Ø§Ù‹ (Ø£ÙˆÙ„ 800 Ù‚Ù†Ø§Ø© Ø¹Ø±Ø¨ÙŠØ© + Ø£ÙˆÙ„ 400 Ù‚Ù†Ø§Ø© Ø¹Ø§Ù„Ù…ÙŠØ©)
        final_list = arabs[:800] + others[:400]
        
        print(f"âœ… ØªÙ… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(final_list)} Ù‚Ù†Ø§Ø© (Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©).")
        
        # Ø§Ù„Ø­ÙØ¸
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(final_list, f, ensure_ascii=False, indent=2)
            
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {OUTPUT_FILE}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙØ§Ø¯Ø­: {e}")
        exit(1)

if __name__ == "__main__":
    main()
